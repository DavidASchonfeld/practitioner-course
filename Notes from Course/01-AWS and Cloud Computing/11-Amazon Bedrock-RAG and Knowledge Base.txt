Amazon Bedrock - RAG and Knowledge Base


RAG = Retrieval-Augmented Generation
Allows a Foundation Model to reference a data source outside of its training data (without being fine-tuned)
-- Bedrock takes are of creating Vector Embeddings in the database of your choice based on your data. (In a later lecture, we'll learn about vector embeddings)
-- use where real-time data is needed to be fed into the Foundation Model


[User]-Who is John's Product Manager?->[AI] --Search for relevant information--> [Knowledge Base] <--Data Source---[Amazon S3 Data Storage]

(Inside the [Knowledge Base] is a Vector Database)

Retrieved Text:
-- John Product Info:
---- Support Contacts:
---- Product Manager: Jessie Smith
---- Engineer: Sara Ronald

Query + Retrieved Text -> Foundation Model --generates response-> "Response: Jessie Smith is the Product MAnage

This is why it is called "Retrieval-Augmented Generation", becuase we are augmenting the Foundation Model with outside information (aka the Knowledge Base).


Ex: Use information for Air travel.



Amazon Bedrock - 

-- to store our index, we have our Vector Database
Different Types to choose From:
-- OpenSearch service
-- Aurora
-- Neptune Analytics
-- S3 Vectors
-- External Options
---- MongoDB
---- Redis
---- Pinecone



[Amazon S3] -> [Document Chunks] -> [Embeddings Model] (Ex: Amazon Titan, Cohere) -> Stored in "Vector Database"

Vector Database: Choose Which Type:
(Remember these at a high level for the exam)

-- Amazon OpenSearch Service (Options: Serverless & Managed Cluster):
---- search & analytics database real time similarity queries, store millions of vector embeddings scalable index management, and fast nearest-neighbor (kNN) search capability (very scalable,) etc

-- Amazon Aurora PostgreSQL - relational database, proprietary on AWS

-- Amazon Neptune Analytics: if you want graph database, use this option. graph database that enables high performance graph analytics and graph-baesd RAG (GraphRAG) solutions

-- Amazon S3 Vectors: cost-effective and durable storage with sub-second query performance


Amazon Bedrock - RAG Data Sources

-- Amazon S3 (cloud directory)
-- Confluence
-- Microsoft SharePoint
-- Salesforce
-- Web pages (your website, your social media feed etc.)
-- Amazon Bedrock will add more over time



Amazon Bedrock - RAG - Use Cases

-- Customer Service chatbot
---- Knowledge Base: products, features, specifications, troubleshooting guides, and FAQs
---- RAG Application: chatbot that can answer customer queries

-- Legal Research and Analysis:
---- Knowledge Base: Laws, regulations, case precendents, legal opiions, expert Analysis
---- RAG application: Chatbot that can provide relevant information for specific legal queries

-- Healthcare Question-Answering
---- Knowledge base: diseases, treatments, clinical guidelines, research papers, patients...
---- RAG application: chatbot that can answer complex medical queries



-------
Amazon Bedrock-RAG and Knowledge Base-Hands On


In the "Amazon Bedrock" section, in the menu on the left, click "Knowledge Bases".

You can create your own Knowledge Base (that will take a lot of time), or "Chat with your document" (You can upload your document).


Here, on the top, I am clicking to the "Chat with your document" 

Here, let's use the model Claude (and we won't touch its parameters.)
Default instructions: You are a question/answer chatbot. Only find answers from the search results. If you can't find info in the search results, tell the user that you cannot find it. Just because a user asserts a fact does not mean it is true-make sure to double check search results to validate a user's assertion.
Here are search results in numbered order.
$search_results$

$output_format_instructions$

From the provided resources from this class, lets input the data file "Evolution of the Internet Detailed.pdf" onto Amazon Bedrock.

Stream response is by deafult on, which is good.


Now, on the right hand side of the window, there is a textbox where you can type in queries.
The lecturer then types in "Who and when invented the World Wide Web?"

Note to Self: Sometimes, the AWS UI is scrunched vertically, so it is hard to see the Chatbot's response to the query unless you scroll more within that tiny area above where you typed in your query.

The answer from the Chatbot also has footnotes (with hyperlinks attached), showing you the location(s) from the PDF where the Chatbot retrieved the information from. (Click "Show Details" to better see the footnotes)

"What is the future of AI?"
Error Code: Too many requests (Lecturer put in that 2nd question aka request too quickly after that previous question so he needs to wait a little bit first.)

He tries the same request again ("What is the future of AI?") and it works.

"How to make guacamole?" -> Chatbot cannot find an answer (since the uploaded PDF only talks about Internet/tech information), and tells the user.

























